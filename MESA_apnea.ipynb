{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b8c1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import pywt\n",
    "\n",
    "# ================== 参数 ====================\n",
    "edf_dir = \"E:/mesa/polysomnography/edfs\"\n",
    "xml_dir = \"E:/mesa/polysomnography/annotations-events-nsrr\"\n",
    "output_base_dir = \"G:/mesa_apnea\"\n",
    "\n",
    "channels = ['EEG2', 'Flow', 'SpO2', 'Thor', 'Abdo']\n",
    "n_files = 100  # 设置为 None 处理所有\n",
    "resample_rate = 100  # Hz，若不想下采样则设为 None\n",
    "denoise_enabled = True\n",
    "normalize_enabled = True\n",
    "epoch_length = 30  # 秒\n",
    "# ===========================================\n",
    "\n",
    "\n",
    "def wavelet_denoise(data, wavelet='sym6', level=5, mode='soft', boundary_mode='symmetric'):\n",
    "    if data.ndim != 2:\n",
    "        raise ValueError(\"输入数据必须为二维\")\n",
    "    denoised_data = np.zeros_like(data)\n",
    "    for i in range(data.shape[0]):\n",
    "        signal = data[i, :]\n",
    "        try:\n",
    "            max_level = pywt.dwt_max_level(len(signal), pywt.Wavelet(wavelet))\n",
    "            level = min(level, max_level)\n",
    "            coeffs = pywt.wavedec(signal, wavelet, level=level, mode=boundary_mode)\n",
    "            sigma = np.median(np.abs(coeffs[-1])) / 0.6745\n",
    "            threshold = sigma * np.sqrt(2 * np.log(len(signal)))\n",
    "            coeffs_thresh = [coeffs[0]] + [pywt.threshold(c, threshold, mode=mode) for c in coeffs[1:]]\n",
    "            rec = pywt.waverec(coeffs_thresh, wavelet, mode=boundary_mode)\n",
    "            denoised_data[i, :len(rec)] = rec[:len(signal)]\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"通道 {i} 去噪失败: {e}\")\n",
    "    return denoised_data\n",
    "\n",
    "def generate_stage_annotations(xml_path, epoch_length=30, total_duration=None):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    stage_events = []\n",
    "    for event in root.iter('ScoredEvent'):\n",
    "        if event.findtext('EventType', '').strip() != 'Stages|Stages':\n",
    "            continue\n",
    "        concept = event.findtext('EventConcept', '')\n",
    "        parts = concept.split('|')\n",
    "        if len(parts) < 2 or not parts[1].isdigit():\n",
    "            continue\n",
    "        raw_label = int(parts[1])\n",
    "        label = 4 if raw_label == 5 else raw_label  # REM=4\n",
    "        if not (0 <= label <= 4):\n",
    "            continue\n",
    "        start = float(event.findtext('Start', '0'))\n",
    "        duration = float(event.findtext('Duration', '0'))\n",
    "        stage_events.append({'start': start, 'end': start + duration, 'label': label})\n",
    "\n",
    "    max_time = total_duration if total_duration is not None else max([e['end'] for e in stage_events] + [0])\n",
    "    total_epochs = math.ceil(max_time / epoch_length)\n",
    "    annotations = [{'epoch': i, 'label': 0} for i in range(total_epochs)]\n",
    "    for e in stage_events:\n",
    "        start_ep = int(e['start'] // epoch_length)\n",
    "        end_ep = int((e['end'] - 1e-9) // epoch_length)\n",
    "        for i in range(start_ep, end_ep + 1):\n",
    "            if 0 <= i < total_epochs:\n",
    "                annotations[i]['label'] = e['label']\n",
    "    return annotations\n",
    "\n",
    "def generate_apnea_annotations_binary(xml_path, epoch_length=30):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    event_map = {\n",
    "        'Central apnea': 1,\n",
    "        'Hypopnea': 1,\n",
    "        'Obstructive apnea': 1\n",
    "    }\n",
    "    apnea_events = []\n",
    "    max_time = 0\n",
    "    for event in root.iter('ScoredEvent'):\n",
    "        concept = event.findtext('EventConcept', '').split('|')[0].strip()\n",
    "        if concept not in event_map:\n",
    "            continue\n",
    "        start = float(event.findtext('Start', '0'))\n",
    "        duration = float(event.findtext('Duration', '0'))\n",
    "        end = start + duration\n",
    "        apnea_events.append({'start': start, 'end': end, 'label': 1})\n",
    "        max_time = max(max_time, end)\n",
    "\n",
    "    total_epochs = math.ceil(max_time / epoch_length)\n",
    "    annotations = [{'epoch': i, 'label': 0} for i in range(total_epochs)]\n",
    "    for e in apnea_events:\n",
    "        start_ep = int(e['start'] // epoch_length)\n",
    "        end_ep = int((e['end'] - 1e-9) // epoch_length)\n",
    "        for i in range(start_ep, end_ep + 1):\n",
    "            if 0 <= i < total_epochs:\n",
    "                annotations[i]['label'] = 1\n",
    "    return annotations, max_time\n",
    "\n",
    "def process_apnea_epoch_segments(edf_path, xml_path, output_dir):\n",
    "    apnea_anns, apnea_max_time = generate_apnea_annotations_binary(xml_path, epoch_length)\n",
    "    stage_anns = generate_stage_annotations(xml_path, epoch_length, apnea_max_time)\n",
    "\n",
    "    raw = mne.io.read_raw(edf_path, preload=True, verbose=False)\n",
    "\n",
    "    if resample_rate:\n",
    "        raw.resample(resample_rate)\n",
    "\n",
    "    if channels:\n",
    "        exist = [ch for ch in channels if ch in raw.ch_names]\n",
    "        raw.pick_channels(exist)\n",
    "\n",
    "    sfreq = raw.info['sfreq']\n",
    "    duration = raw.n_times / sfreq\n",
    "    max_time = min(duration, apnea_max_time)\n",
    "    aligned_time = (max_time // epoch_length) * epoch_length\n",
    "    raw.crop(tmax=aligned_time)\n",
    "\n",
    "    data = raw.get_data()\n",
    "    total_epochs = int(aligned_time // epoch_length)\n",
    "    apnea_anns = apnea_anns[:total_epochs]\n",
    "    stage_anns = stage_anns[:total_epochs]\n",
    "    samples_per_epoch = int(epoch_length * sfreq)\n",
    "\n",
    "    if denoise_enabled:\n",
    "        eeg_chs = [i for i, name in enumerate(raw.ch_names) if 'EEG' in name]\n",
    "        if eeg_chs:\n",
    "            data[eeg_chs, :] = wavelet_denoise(data[eeg_chs, :])\n",
    "\n",
    "    if normalize_enabled:\n",
    "        mask = np.array([ch != 'SpO2' for ch in raw.ch_names])\n",
    "        if np.any(mask):\n",
    "            mean = data[mask].mean(axis=1, keepdims=True)\n",
    "            std = data[mask].std(axis=1, keepdims=True)\n",
    "            std[std == 0] = 1\n",
    "            data[mask] = (data[mask] - mean) / std\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    saved = 0\n",
    "    for i in range(total_epochs):\n",
    "        if stage_anns[i]['label'] == 0:\n",
    "            continue  # 跳过醒期\n",
    "        label = apnea_anns[i]['label']\n",
    "        seg = data[:, i * samples_per_epoch: (i + 1) * samples_per_epoch]\n",
    "        filename = f\"ep{i:04d}_label{label}.npy\"\n",
    "        np.save(os.path.join(output_dir, filename), seg)\n",
    "        saved += 1\n",
    "\n",
    "    print(f\"[INFO] {os.path.basename(edf_path)}: 共保存 {saved} 个非清醒期片段\")\n",
    "\n",
    "# ========== 主循环 ==========\n",
    "if __name__ == \"__main__\":\n",
    "    edf_files = glob.glob(os.path.join(edf_dir, \"mesa-sleep-*.edf\"))\n",
    "    edf_files.sort(key=lambda x: int(re.search(r\"mesa-sleep-(\\d+)\\.edf\", x).group(1)))\n",
    "\n",
    "    if isinstance(n_files, int):\n",
    "        edf_files = edf_files[:n_files]\n",
    "\n",
    "    print(f\"[INFO] 处理 {len(edf_files)} 个文件\")\n",
    "    for idx, edf_path in enumerate(edf_files, 1):\n",
    "        try:\n",
    "            file_id = re.search(r\"mesa-sleep-(\\d+)\\.edf\", os.path.basename(edf_path)).group(1)\n",
    "            xml_path = os.path.join(xml_dir, f\"mesa-sleep-{file_id}-nsrr.xml\")\n",
    "            output_dir = os.path.join(output_base_dir, file_id)\n",
    "            if not os.path.exists(xml_path):\n",
    "                print(f\"[SKIP] 缺失标注文件: {xml_path}\")\n",
    "                continue\n",
    "            print(f\"\\n[{idx}/{len(edf_files)}] 处理文件: {file_id}\")\n",
    "            process_apnea_epoch_segments(edf_path, xml_path, output_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] 文件 {edf_path} 处理失败: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9f3138",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleep3.8",
   "language": "python",
   "name": "sleep3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
