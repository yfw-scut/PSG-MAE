{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f3ff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "from tqdm import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "ANNOTATION_MAP = {\n",
    "    \"Wake|0\": 0, \n",
    "    \"Stage 1 sleep|1\": 1, \n",
    "    \"Stage 2 sleep|2\": 2, \n",
    "    \"Stage 3 sleep|3\": 3,\n",
    "    \"Stage 4 sleep|4\": 3,\n",
    "    \"REM sleep|5\": 4,\n",
    "    \"Unscored|9\": 5,\n",
    "    \"Movement|6\": 6\n",
    "}\n",
    "\n",
    "OSA_EVENTS = ['Central apnea', 'Hypopnea', 'Obstructive apnea']\n",
    "CHANNEL_PRIORITY = {\n",
    "    'EOG': ['EOG(L)', 'EOG', 'EOGL'],\n",
    "    'EMG': ['EMG'],\n",
    "    'AIRFLOW': ['NEW AIR', 'AIRFLOW']\n",
    "}\n",
    "\n",
    "def _safe_tmax_for_crop(raw, tmax, file_id=\"unknown\"):\n",
    "    \"\"\"安全裁剪时间范围避免越界\"\"\"\n",
    "    last = float(raw.times[-1])\n",
    "    t0 = float(tmax)\n",
    "    tmax = min(t0, last)\n",
    "    if not (tmax < last):\n",
    "        tmax = np.nextafter(last, -np.inf)\n",
    "    if tmax < 0.0:\n",
    "        tmax = 0.0\n",
    "    return float(tmax)\n",
    "\n",
    "def normalize_per_channel(signal):\n",
    "    \"\"\"对每个通道进行标准化处理\"\"\"\n",
    "    epsilon = 1e-8\n",
    "    means = np.mean(signal, axis=1, keepdims=True)\n",
    "    stds = np.std(signal, axis=1, keepdims=True) + epsilon\n",
    "    return (signal - means) / stds\n",
    "\n",
    "def read_and_preprocess_edf(file_path):\n",
    "    \"\"\"读取并预处理EDF文件\"\"\"\n",
    "    try:\n",
    "        raw = mne.io.read_raw_edf(file_path, preload=True, verbose='ERROR')\n",
    "        if 'EEG' not in raw.ch_names:\n",
    "            return None, None\n",
    "        if not any(ch in raw.ch_names for ch in ['NEW AIR', 'AIRFLOW']):\n",
    "            return None, None\n",
    "        ch_name_mapping = {}\n",
    "        used_target_names = set()\n",
    "        for target_name, variants in CHANNEL_PRIORITY.items():\n",
    "            for ch in variants:\n",
    "                if ch in raw.ch_names:\n",
    "                    if target_name not in raw.ch_names and target_name not in used_target_names:\n",
    "                        ch_name_mapping[ch] = target_name\n",
    "                        used_target_names.add(target_name)\n",
    "                        break\n",
    "        if ch_name_mapping:\n",
    "            raw.rename_channels(ch_name_mapping)\n",
    "        ch_type_mapping = {\n",
    "            'EOG': 'eog',\n",
    "            'EMG': 'emg',\n",
    "            'AIRFLOW': 'misc'\n",
    "        }\n",
    "        raw.set_channel_types(ch_type_mapping)\n",
    "        duration = raw.n_times / raw.info['sfreq']\n",
    "        return raw, duration\n",
    "    except Exception as e:\n",
    "        return None, None\n",
    "\n",
    "def select_channels(raw):\n",
    "    \"\"\"选择需要的信号通道\"\"\"\n",
    "    if 'EEG' not in raw.info['ch_names']:\n",
    "        return None\n",
    "    eeg_channel = 'EEG'\n",
    "    eeg2_variants = ['EEG2', 'EEG 2', 'EEG(SEC)', 'EEG(sec)']\n",
    "    eeg2_channel = next((ch for ch in eeg2_variants if ch in raw.info['ch_names']), None)\n",
    "    if eeg2_channel is None:\n",
    "        return None\n",
    "    eog_channel = next((ch for ch in raw.info['ch_names'] if 'EOG' in ch), None)\n",
    "    emg_channel = next((ch for ch in raw.info['ch_names'] if 'EMG' in ch), None)\n",
    "    if not eog_channel or not emg_channel:\n",
    "        return None\n",
    "    if 'NEW AIR' in raw.info['ch_names']:\n",
    "        airflow_channel = 'NEW AIR'\n",
    "    elif 'AIRFLOW' in raw.info['ch_names']:\n",
    "        airflow_channel = 'AIRFLOW'\n",
    "    else:\n",
    "        return None\n",
    "    return [eeg2_channel, eeg_channel, eog_channel, emg_channel, airflow_channel]\n",
    "\n",
    "def parse_sleep_annotations(annotation_path):\n",
    "    \"\"\"解析睡眠分期注释\"\"\"\n",
    "    try:\n",
    "        tree = ET.parse(annotation_path)\n",
    "        root = tree.getroot()\n",
    "        events = []\n",
    "        for scored_event in root.findall('.//ScoredEvent'):\n",
    "            event_type = scored_event.find('EventType').text\n",
    "            if event_type != \"Stages|Stages\":\n",
    "                continue\n",
    "            description = scored_event.find('EventConcept').text\n",
    "            start = float(scored_event.find('Start').text)\n",
    "            duration = float(scored_event.find('Duration').text)\n",
    "            if description not in ANNOTATION_MAP:\n",
    "                continue\n",
    "            events.append({\n",
    "                'onset': start,\n",
    "                'duration': duration,\n",
    "                'description': description,\n",
    "                'stage': ANNOTATION_MAP[description]\n",
    "            })\n",
    "        return events\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def extract_osa_events(annotation_path):\n",
    "    \"\"\"提取睡眠呼吸暂停事件\"\"\"\n",
    "    try:\n",
    "        tree = ET.parse(annotation_path)\n",
    "        root = tree.getroot()\n",
    "        events = []\n",
    "        for scored_event in root.findall('.//ScoredEvent'):\n",
    "            event_concept = scored_event.find('EventConcept').text\n",
    "            event_type = event_concept.split('|')[0].strip()\n",
    "            if event_type in OSA_EVENTS:\n",
    "                start = float(scored_event.find('Start').text)\n",
    "                duration = float(scored_event.find('Duration').text)\n",
    "                if duration >= 10:\n",
    "                    events.append({\n",
    "                        'start': start,\n",
    "                        'duration': duration,\n",
    "                        'end': start + duration,\n",
    "                        'type': event_type\n",
    "                    })\n",
    "        return events\n",
    "    except Exception as e:\n",
    "        return []\n",
    "\n",
    "def process_raw_data(raw, sleep_events, resample_freq=100):\n",
    "    \"\"\"处理原始数据并创建epochs\"\"\"\n",
    "    annotations = mne.Annotations(\n",
    "        onset=[e['onset'] for e in sleep_events],\n",
    "        duration=[e['duration'] for e in sleep_events],\n",
    "        description=[e['description'] for e in sleep_events]\n",
    "    )\n",
    "    raw.set_annotations(annotations)\n",
    "    if 'EEG' in raw.ch_names:\n",
    "        raw.filter(l_freq=0.1, h_freq=40, picks=['EEG'], method='fir', fir_window='hamming', phase='zero')\n",
    "    data_array = raw.get_data()\n",
    "    normalized_data = normalize_per_channel(data_array)\n",
    "    raw._data = normalized_data\n",
    "    if raw.info['sfreq'] > resample_freq:\n",
    "        raw.resample(resample_freq, npad='auto')\n",
    "    events_from_annot, event_id = mne.events_from_annotations(\n",
    "        raw, \n",
    "        event_id=ANNOTATION_MAP,\n",
    "        chunk_duration=30.0\n",
    "    )\n",
    "    tmax = 30.0 - 1.0 / raw.info['sfreq']\n",
    "    safe_tmax = _safe_tmax_for_crop(raw, tmax)\n",
    "    try:\n",
    "        epochs = mne.Epochs(\n",
    "            raw,\n",
    "            events=events_from_annot,\n",
    "            event_id=event_id,\n",
    "            tmin=0.0,\n",
    "            tmax=safe_tmax,\n",
    "            baseline=None,\n",
    "            preload=True,\n",
    "            verbose=False\n",
    "        )\n",
    "        return epochs\n",
    "    except ValueError as e:\n",
    "        return None\n",
    "\n",
    "def process_subject(raw, epochs, osa_events, file_index):\n",
    "    \"\"\"处理单个受试者数据并保存结果\"\"\"\n",
    "    sfreq = raw.info['sfreq']\n",
    "    saved_count = 0\n",
    "    output_dir = f\"F:/SHHS2_apnea/SHHS2_{file_index:04d}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for i in range(len(epochs)):\n",
    "        stage = epochs.events[i, 2]\n",
    "        if stage in [0, 5, 6]:\n",
    "            continue\n",
    "        start_sample = epochs.events[i, 0]\n",
    "        epoch_start = start_sample / sfreq\n",
    "        epoch_end = epoch_start + 30.0\n",
    "        osa_label = 0\n",
    "        has_significant_overlap = False\n",
    "        for event in osa_events:\n",
    "            event_end = event['start'] + event['duration']\n",
    "            overlap_start = max(event['start'], epoch_start)\n",
    "            overlap_end = min(event_end, epoch_end)\n",
    "            overlap_duration = overlap_end - overlap_start\n",
    "            if overlap_duration >= 6:\n",
    "                has_significant_overlap = True\n",
    "                break\n",
    "        if has_significant_overlap:\n",
    "            osa_label = 1\n",
    "        epoch_data = epochs.get_data(item=i)[0]\n",
    "        file_name = f\"e_{saved_count:04d}_{osa_label}.npy\"\n",
    "        np.save(os.path.join(output_dir, file_name), epoch_data)\n",
    "        saved_count += 1\n",
    "    return saved_count\n",
    "\n",
    "def match_psg_annotation_files(psg_dir, annotation_dir):\n",
    "    \"\"\"匹配PSG和标注文件\"\"\"\n",
    "    psg_files = [f for f in os.listdir(psg_dir) if f.endswith('.edf')]\n",
    "    file_map = {}\n",
    "    for psg_file in psg_files:\n",
    "        base_id = re.sub(r'\\.edf$', '', psg_file)\n",
    "        base_id = re.sub(r'[\\-_].*$', '', base_id)\n",
    "        annotation_candidates = [\n",
    "            f for f in os.listdir(annotation_dir)\n",
    "            if f.startswith(base_id) and f.endswith('.xml')\n",
    "        ]\n",
    "        if annotation_candidates:\n",
    "            annotation_file = sorted(annotation_candidates, key=len, reverse=True)[0]\n",
    "            file_map[psg_file] = annotation_file\n",
    "    return file_map\n",
    "\n",
    "def main():\n",
    "    \"\"\"主处理函数\"\"\"\n",
    "    ANNOTATION_DIR = \"D:/shhs/polysomnography/annotations-events-nsrr/shhs2\"\n",
    "    PSG_DIR = \"D:/shhs/polysomnography/edfs/shhs2\"\n",
    "    OUTPUT_DIR = \"F:/SHHS2_apnea\"\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    file_map = match_psg_annotation_files(PSG_DIR, ANNOTATION_DIR)\n",
    "    processed_files = 0\n",
    "    total_epochs = 0\n",
    "    for psg_file, annotation_file in tqdm(file_map.items(), desc=\"Processing files\"):\n",
    "        psg_path = os.path.join(PSG_DIR, psg_file)\n",
    "        annotation_path = os.path.join(ANNOTATION_DIR, annotation_file)\n",
    "        raw, duration = read_and_preprocess_edf(psg_path)\n",
    "        if raw is None:\n",
    "            continue\n",
    "        picked_channels = select_channels(raw)\n",
    "        if picked_channels is None:\n",
    "            continue\n",
    "        sleep_events = parse_sleep_annotations(annotation_path)\n",
    "        if sleep_events is None or not sleep_events:\n",
    "            continue\n",
    "        osa_events = extract_osa_events(annotation_path)\n",
    "        raw.pick_channels(picked_channels)\n",
    "        epochs = process_raw_data(raw, sleep_events, resample_freq=100)\n",
    "        if epochs is None or len(epochs) == 0:\n",
    "            continue\n",
    "        file_index = processed_files + 1\n",
    "        epoch_count = process_subject(raw, epochs, osa_events, file_index)\n",
    "        total_epochs += epoch_count\n",
    "        processed_files += 1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e78bf41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleep3.8",
   "language": "python",
   "name": "sleep3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
