{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1576f6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "from tqdm import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "# 睡眠分期映射\n",
    "ANNOTATION_MAP = {\n",
    "    \"Wake|0\": 0, \n",
    "    \"Stage 1 sleep|1\": 1, \n",
    "    \"Stage 2 sleep|2\": 2, \n",
    "    \"Stage 3 sleep|3\": 3,\n",
    "    \"Stage 4 sleep|4\": 3,  # Stage 4 映射到 N3\n",
    "    \"REM sleep|5\": 4,\n",
    "    \"Unscored|9\": 5,\n",
    "    \"Movement|6\": 6\n",
    "}\n",
    "\n",
    "# OSA事件类型\n",
    "OSA_EVENTS = ['Central apnea', 'Hypopnea', 'Obstructive apnea']\n",
    "CHANNEL_PRIORITY = {\n",
    "    'EOG': ['EOG(L)', 'EOG', 'EOGL'],\n",
    "    'EMG': ['EMG'],\n",
    "    'ECG': ['ECG'],\n",
    "    'AIRFLOW': ['NEW AIR', 'AIRFLOW']\n",
    "}\n",
    "\n",
    "def normalize_per_channel(signal):\n",
    "    epsilon = 1e-8\n",
    "    means = np.mean(signal, axis=1, keepdims=True)\n",
    "    stds = np.std(signal, axis=1, keepdims=True) + epsilon\n",
    "    return (signal - means) / stds\n",
    "\n",
    "def read_and_preprocess_edf(file_path):\n",
    "    \"\"\"读取EDF文件并进行预处理\"\"\"\n",
    "    try:\n",
    "        raw = mne.io.read_raw_edf(\n",
    "            file_path, \n",
    "            infer_types=True, \n",
    "            preload=True, \n",
    "            verbose='ERROR'\n",
    "        )\n",
    "\n",
    "        if 'EEG' not in raw.ch_names:\n",
    "            print(f\"文件 {os.path.basename(file_path)} 缺少主 EEG 通道\")\n",
    "            return None, None\n",
    "        if not any(ch in raw.ch_names for ch in ['NEW AIR', 'AIRFLOW']):\n",
    "            print(f\"文件 {os.path.basename(file_path)} 缺少 AIRFLOW 通道\")\n",
    "            return None, None\n",
    "\n",
    "        # 通道重命名\n",
    "        ch_name_mapping = {}\n",
    "        used_target_names = set()\n",
    "        for target_name, variants in CHANNEL_PRIORITY.items():\n",
    "            for ch in variants:\n",
    "                if ch in raw.ch_names:\n",
    "                    if target_name not in raw.ch_names and target_name not in used_target_names:\n",
    "                        ch_name_mapping[ch] = target_name\n",
    "                        used_target_names.add(target_name)\n",
    "                        break\n",
    "\n",
    "        if ch_name_mapping:\n",
    "            raw.rename_channels(ch_name_mapping)\n",
    "\n",
    "        # 设置通道类型\n",
    "        ch_type_mapping = {\n",
    "            'EOG': 'eog',\n",
    "            'EMG': 'emg',\n",
    "            'ECG': 'ecg',\n",
    "            'AIRFLOW': 'misc'\n",
    "        }\n",
    "        raw.set_channel_types(ch_type_mapping)\n",
    "\n",
    "        duration = raw.n_times / raw.info['sfreq']\n",
    "        return raw, duration\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"读取EDF文件失败: {file_path}, 错误: {str(e)}\")\n",
    "        return None, None\n",
    "\n",
    "def select_channels(raw):\n",
    "    \"\"\"选择所需的通道\"\"\"\n",
    "    if 'EEG' not in raw.info['ch_names']:\n",
    "        return None\n",
    "    eeg_channel = 'EEG'\n",
    "\n",
    "    eeg2_variants = ['EEG2', 'EEG 2', 'EEG(SEC)', 'EEG(sec)']\n",
    "    eeg2_channel = next((ch for ch in eeg2_variants if ch in raw.info['ch_names']), None)\n",
    "    if eeg2_channel is None:\n",
    "        return None\n",
    "\n",
    "    eog_channel = next((ch for ch in raw.info['ch_names'] if 'EOG' in ch), None)\n",
    "    emg_channel = next((ch for ch in raw.info['ch_names'] if 'EMG' in ch), None)\n",
    "    if not eog_channel or not emg_channel:\n",
    "        return None\n",
    "\n",
    "    if 'NEW AIR' in raw.info['ch_names']:\n",
    "        airflow_channel = 'NEW AIR'\n",
    "    elif 'AIRFLOW' in raw.info['ch_names']:\n",
    "        airflow_channel = 'AIRFLOW'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    return [eeg2_channel, eeg_channel, eog_channel, emg_channel, airflow_channel]\n",
    "\n",
    "def parse_sleep_annotations(annotation_path):\n",
    "    \"\"\"解析睡眠分期注释\"\"\"\n",
    "    try:\n",
    "        tree = ET.parse(annotation_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        events = []\n",
    "        for scored_event in root.findall('.//ScoredEvent'):\n",
    "            event_type = scored_event.find('EventType').text\n",
    "            if event_type != \"Stages|Stages\":\n",
    "                continue\n",
    "\n",
    "            description = scored_event.find('EventConcept').text\n",
    "            start = float(scored_event.find('Start').text)\n",
    "            duration = float(scored_event.find('Duration').text)\n",
    "\n",
    "            if description not in ANNOTATION_MAP:\n",
    "                continue\n",
    "\n",
    "            events.append({\n",
    "                'onset': start,\n",
    "                'duration': duration,\n",
    "                'description': description,\n",
    "                'stage': ANNOTATION_MAP[description]\n",
    "            })\n",
    "\n",
    "        return events\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"解析注释文件失败: {annotation_path}, 错误: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def extract_osa_events(annotation_path):\n",
    "    \"\"\"提取睡眠呼吸暂停事件\"\"\"\n",
    "    try:\n",
    "        tree = ET.parse(annotation_path)\n",
    "        root = tree.getroot()\n",
    "        events = []\n",
    "        \n",
    "        for scored_event in root.findall('.//ScoredEvent'):\n",
    "            event_concept = scored_event.find('EventConcept').text\n",
    "            event_type = event_concept.split('|')[0].strip()\n",
    "            \n",
    "            if event_type in OSA_EVENTS:\n",
    "                start = float(scored_event.find('Start').text)\n",
    "                duration = float(scored_event.find('Duration').text)\n",
    "                events.append({\n",
    "                    'start': start,\n",
    "                    'duration': duration,\n",
    "                    'end': start + duration\n",
    "                })\n",
    "                \n",
    "        return events\n",
    "    except Exception as e:\n",
    "        print(f\"解析呼吸事件失败: {annotation_path}, 错误: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "def process_raw_data(raw, sleep_events, resample_freq=100):\n",
    "    \"\"\"处理原始数据并创建epochs\"\"\"\n",
    "    annotations = mne.Annotations(\n",
    "        onset=[e['onset'] for e in sleep_events],\n",
    "        duration=[e['duration'] for e in sleep_events],\n",
    "        description=[e['description'] for e in sleep_events]\n",
    "    )\n",
    "    raw.set_annotations(annotations)\n",
    "\n",
    "    if 'EEG' in raw.ch_names:\n",
    "        raw.filter(l_freq=0.1, h_freq=40, picks=['EEG'], method='fir', fir_window='hamming', phase='zero')\n",
    "\n",
    "    data_array = raw.get_data()\n",
    "    normalized_data = normalize_per_channel(data_array)\n",
    "    raw._data = normalized_data\n",
    "\n",
    "    if raw.info['sfreq'] > resample_freq:\n",
    "        raw.resample(resample_freq, npad='auto')\n",
    "\n",
    "    events_from_annot, event_id = mne.events_from_annotations(\n",
    "        raw, \n",
    "        event_id=ANNOTATION_MAP,\n",
    "        chunk_duration=30.0\n",
    "    )\n",
    "\n",
    "    tmax = 30.0 - 1.0 / raw.info['sfreq']\n",
    "    try:\n",
    "        epochs = mne.Epochs(\n",
    "            raw,\n",
    "            events=events_from_annot,\n",
    "            event_id=event_id,\n",
    "            tmin=0.0,\n",
    "            tmax=tmax,\n",
    "            baseline=None,\n",
    "            preload=True,\n",
    "            verbose=False\n",
    "        )\n",
    "        return epochs\n",
    "    except ValueError as e:\n",
    "        print(f\"创建Epochs失败: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def process_subject(raw, epochs, osa_events, file_index):\n",
    "    \"\"\"处理单个受试者数据并保存结果\"\"\"\n",
    "    sfreq = raw.info['sfreq']\n",
    "    saved_count = 0\n",
    "    \n",
    "    # 创建输出目录\n",
    "    output_dir = f\"F:/SHHS_Apnea/SHHS1_{file_index:04d}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 遍历所有epoch\n",
    "    for i in range(len(epochs)):\n",
    "        # 获取当前epoch的睡眠分期\n",
    "        stage = epochs.events[i, 2]\n",
    "        \n",
    "        # 跳过清醒期(W)和其他无效分期\n",
    "        if stage in [0, 5, 6]:\n",
    "            continue\n",
    "            \n",
    "        # 计算epoch的绝对时间\n",
    "        start_sample = epochs.events[i, 0]\n",
    "        epoch_start = start_sample / sfreq\n",
    "        epoch_end = epoch_start + 30.0\n",
    "        \n",
    "        # 检查是否包含OSA事件\n",
    "        osa_label = 0\n",
    "        for event in osa_events:\n",
    "            event_end = event['start'] + event['duration']\n",
    "            # 检查事件是否与当前epoch重叠\n",
    "            if event['start'] < epoch_end and event_end > epoch_start:\n",
    "                osa_label = 1\n",
    "                break\n",
    "                \n",
    "        # 获取epoch数据\n",
    "        epoch_data = epochs.get_data(item=i)[0]  # (n_channels, n_times)\n",
    "        \n",
    "        # 保存文件\n",
    "        file_name = f\"e_{saved_count:04d}_{osa_label}.npy\"\n",
    "        np.save(os.path.join(output_dir, file_name), epoch_data)\n",
    "        saved_count += 1\n",
    "        \n",
    "    return saved_count\n",
    "\n",
    "def match_psg_annotation_files(psg_dir, annotation_dir):\n",
    "    \"\"\"匹配PSG文件和注释文件\"\"\"\n",
    "    psg_files = [f for f in os.listdir(psg_dir) if f.endswith('.edf')]\n",
    "    file_map = {}\n",
    "    for psg_file in psg_files:\n",
    "        base_id = re.sub(r'\\.edf$', '', psg_file)\n",
    "        base_id = re.sub(r'[\\-_].*$', '', base_id)\n",
    "        annotation_candidates = [\n",
    "            f for f in os.listdir(annotation_dir)\n",
    "            if f.startswith(base_id) and f.endswith('.xml')\n",
    "        ]\n",
    "        if annotation_candidates:\n",
    "            annotation_file = sorted(annotation_candidates, key=len, reverse=True)[0]\n",
    "            file_map[psg_file] = annotation_file\n",
    "    return file_map\n",
    "\n",
    "def main():\n",
    "    ANNOTATION_DIR = \"D:/shhs/polysomnography/annotations-events-nsrr/shhs1\"\n",
    "    PSG_DIR = \"D:/shhs/polysomnography/edfs/shhs1\"\n",
    "    OUTPUT_DIR = \"F:/SHHS_apnea\"\n",
    "    \n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    file_map = match_psg_annotation_files(PSG_DIR, ANNOTATION_DIR)\n",
    "    print(f\"找到 {len(file_map)} 对匹配的文件\")\n",
    "    processed_files = 0\n",
    "    total_epochs = 0\n",
    "\n",
    "    for psg_file, annotation_file in tqdm(file_map.items(), desc=\"Processing files\"):\n",
    "        psg_path = os.path.join(PSG_DIR, psg_file)\n",
    "        annotation_path = os.path.join(ANNOTATION_DIR, annotation_file)\n",
    "        \n",
    "        # 步骤1: 读取并预处理EDF文件\n",
    "        raw, duration = read_and_preprocess_edf(psg_path)\n",
    "        if raw is None:\n",
    "            continue\n",
    "            \n",
    "        # 步骤2: 选择通道\n",
    "        picked_channels = select_channels(raw)\n",
    "        if picked_channels is None:\n",
    "            continue\n",
    "            \n",
    "        # 步骤3: 解析睡眠分期\n",
    "        sleep_events = parse_sleep_annotations(annotation_path)\n",
    "        if sleep_events is None or not sleep_events:\n",
    "            continue\n",
    "            \n",
    "        # 步骤4: 解析OSA事件\n",
    "        osa_events = extract_osa_events(annotation_path)\n",
    "        \n",
    "        # 步骤5: 处理原始数据并创建epochs\n",
    "        raw.pick_channels(picked_channels)\n",
    "        epochs = process_raw_data(raw, sleep_events, resample_freq=100)\n",
    "        if epochs is None or len(epochs) == 0:\n",
    "            continue\n",
    "            \n",
    "        # 步骤6: 处理并保存结果\n",
    "        file_index = processed_files + 1\n",
    "        epoch_count = process_subject(raw, epochs, osa_events, file_index)\n",
    "        total_epochs += epoch_count\n",
    "        \n",
    "        processed_files += 1\n",
    "        print(f\"已处理 {processed_files} 个文件, 保存了 {epoch_count} 个epochs\")\n",
    "\n",
    "    print(\"\\n处理完成!\")\n",
    "    print(f\"共处理 {processed_files} 个受试者\")\n",
    "    print(f\"共保存 {total_epochs} 个有效epochs\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22767f92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleep3.8",
   "language": "python",
   "name": "sleep3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
