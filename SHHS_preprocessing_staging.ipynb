{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1119b9b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mne\n",
    "from tqdm import tqdm\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "\n",
    "ANNOTATION_MAP = {\n",
    "    \"Wake|0\": 0, \n",
    "    \"Stage 1 sleep|1\": 1, \n",
    "    \"Stage 2 sleep|2\": 2, \n",
    "    \"Stage 3 sleep|3\": 3,\n",
    "    \"Stage 4 sleep|4\": 3,  # Stage 4 映射到 N3\n",
    "    \"REM sleep|5\": 4,\n",
    "    \"Unscored|9\": 5,\n",
    "    \"Movement|6\": 6\n",
    "}\n",
    "\n",
    "CHANNEL_PRIORITY = {\n",
    "    'EOG': ['EOG(L)', 'EOG', 'EOGL'],\n",
    "    'EMG': ['EMG'],\n",
    "    'ECG': ['ECG'],\n",
    "    'AIRFLOW': ['NEW AIR', 'AIRFLOW']\n",
    "}\n",
    "\n",
    "STAGE_NAMES = {0: \"W\", 1: \"N1\", 2: \"N2\", 3: \"N3\", 4: \"R\"}\n",
    "\n",
    "def normalize_per_channel(signal):\n",
    "    epsilon = 1e-8\n",
    "    means = np.mean(signal, axis=1, keepdims=True)\n",
    "    stds = np.std(signal, axis=1, keepdims=True) + epsilon\n",
    "    return (signal - means) / stds\n",
    "\n",
    "def read_and_preprocess_edf(file_path):\n",
    "    \"\"\"\n",
    "    读取EDF文件并进行预处理（避免重命名冲突，只设置必要通道类型）\n",
    "    返回 Raw 对象和持续时间\n",
    "    \"\"\"\n",
    "    try:\n",
    "        raw = mne.io.read_raw_edf(\n",
    "            file_path, \n",
    "            infer_types=True, \n",
    "            preload=True, \n",
    "            verbose='ERROR'\n",
    "        )\n",
    "\n",
    "        # 必须有 EEG 和 AIRFLOW（NEW AIR 或 AIRFLOW）\n",
    "        if 'EEG' not in raw.ch_names:\n",
    "            print(f\"文件 {os.path.basename(file_path)} 缺少主 EEG 通道\")\n",
    "            return None, None\n",
    "        if not any(ch in raw.ch_names for ch in ['NEW AIR', 'AIRFLOW']):\n",
    "            print(f\"文件 {os.path.basename(file_path)} 缺少 AIRFLOW 通道\")\n",
    "            return None, None\n",
    "\n",
    "        # 安全构建通道重命名映射（排除冲突）\n",
    "        ch_name_mapping = {}\n",
    "        used_target_names = set()\n",
    "        for target_name, variants in CHANNEL_PRIORITY.items():\n",
    "            for ch in variants:\n",
    "                if ch in raw.ch_names:\n",
    "                    # 避免重命名为已经存在的通道名，例如 EEG → EEG\n",
    "                    if target_name not in raw.ch_names and target_name not in used_target_names:\n",
    "                        ch_name_mapping[ch] = target_name\n",
    "                        used_target_names.add(target_name)\n",
    "                        break\n",
    "\n",
    "        if ch_name_mapping:\n",
    "            raw.rename_channels(ch_name_mapping)\n",
    "\n",
    "        # 设置通道类型（不包括 EEG）\n",
    "        ch_type_mapping = {\n",
    "            'EOG': 'eog',\n",
    "            'EMG': 'emg',\n",
    "            'ECG': 'ecg',\n",
    "            'AIRFLOW': 'misc'\n",
    "        }\n",
    "        raw.set_channel_types(ch_type_mapping)\n",
    "\n",
    "        duration = raw.n_times / raw.info['sfreq']\n",
    "        return raw, duration\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"读取EDF文件失败: {file_path}, 错误: {str(e)}\")\n",
    "        return None, None\n",
    "    \n",
    "def select_channels(raw):\n",
    "    if 'EEG' not in raw.info['ch_names']:\n",
    "        print(\"主 EEG 通道 'EEG' 缺失，跳过此文件。\")\n",
    "        return None\n",
    "    eeg_channel = 'EEG'\n",
    "\n",
    "    eeg2_variants = ['EEG2', 'EEG 2', 'EEG(SEC)', 'EEG(sec)']\n",
    "    eeg2_channel = next((ch for ch in eeg2_variants if ch in raw.info['ch_names']), None)\n",
    "    if eeg2_channel is None:\n",
    "        print(\"第二 EEG 通道缺失，跳过此文件。\")\n",
    "        return None\n",
    "\n",
    "    eog_channel = next((ch for ch in raw.info['ch_names'] if 'EOG' in ch), None)\n",
    "    emg_channel = next((ch for ch in raw.info['ch_names'] if 'EMG' in ch), None)\n",
    "    if not eog_channel or not emg_channel:\n",
    "        print(\"EOG 或 EMG 通道缺失，跳过此文件。\")\n",
    "        return None\n",
    "\n",
    "    if 'NEW AIR' in raw.info['ch_names']:\n",
    "        airflow_channel = 'NEW AIR'\n",
    "    elif 'AIRFLOW' in raw.info['ch_names']:\n",
    "        airflow_channel = 'AIRFLOW'\n",
    "    else:\n",
    "        print(\"AIRFLOW 通道缺失，跳过此文件。\")\n",
    "        return None\n",
    "\n",
    "    return [eeg2_channel, eeg_channel, eog_channel, emg_channel, airflow_channel]\n",
    "\n",
    "def parse_sleep_annotations(annotations_path):\n",
    "    try:\n",
    "        tree = ET.parse(annotations_path)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        events = []\n",
    "        for scored_event in root.findall('.//ScoredEvent'):\n",
    "            event_type = scored_event.find('EventType').text\n",
    "            if event_type != \"Stages|Stages\":\n",
    "                continue\n",
    "\n",
    "            description = scored_event.find('EventConcept').text\n",
    "            start = float(scored_event.find('Start').text)\n",
    "            duration = float(scored_event.find('Duration').text)\n",
    "\n",
    "            if description not in ANNOTATION_MAP:\n",
    "                continue\n",
    "\n",
    "            events.append({\n",
    "                'onset': start,\n",
    "                'duration': duration,\n",
    "                'description': description,\n",
    "                'stage': ANNOTATION_MAP[description]\n",
    "            })\n",
    "\n",
    "        return events\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"解析注释文件失败: {annotations_path}, 错误: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def process_raw_data(raw, sleep_events, resample_freq=100):\n",
    "    annotations = mne.Annotations(\n",
    "        onset=[e['onset'] for e in sleep_events],\n",
    "        duration=[e['duration'] for e in sleep_events],\n",
    "        description=[e['description'] for e in sleep_events]\n",
    "    )\n",
    "    raw.set_annotations(annotations)\n",
    "\n",
    "    if 'EEG' in raw.ch_names:\n",
    "        raw.filter(l_freq=0.1, h_freq=40, picks=['EEG'], method='fir', fir_window='hamming', phase='zero')\n",
    "\n",
    "    data_array = raw.get_data()\n",
    "    normalized_data = normalize_per_channel(data_array)\n",
    "    raw._data = normalized_data\n",
    "\n",
    "    if raw.info['sfreq'] > resample_freq:\n",
    "        raw.resample(resample_freq, npad='auto')\n",
    "\n",
    "    events_from_annot, event_id = mne.events_from_annotations(\n",
    "        raw, \n",
    "        event_id=ANNOTATION_MAP,\n",
    "        chunk_duration=30.0\n",
    "    )\n",
    "\n",
    "    tmax = 30.0 - 1.0 / raw.info['sfreq']\n",
    "    try:\n",
    "        epochs = mne.Epochs(\n",
    "            raw,\n",
    "            events=events_from_annot,\n",
    "            event_id=event_id,\n",
    "            tmin=0.0,\n",
    "            tmax=tmax,\n",
    "            baseline=None,\n",
    "            preload=True,\n",
    "            verbose=False\n",
    "        )\n",
    "        return epochs\n",
    "    except ValueError as e:\n",
    "        print(f\"创建Epochs失败: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def save_epochs_to_npy(epochs, output_dir, file_id, file_index):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    stage_counts = {stage: 0 for stage in STAGE_NAMES.keys()}\n",
    "    subfolder_name = f\"SHHS1_{file_index:04d}\"\n",
    "    subfolder_path = os.path.join(output_dir, subfolder_name)\n",
    "    os.makedirs(subfolder_path, exist_ok=True)\n",
    "\n",
    "    for i in range(len(epochs)):\n",
    "        epoch_data = epochs.get_data(item=i)\n",
    "        epoch_label = epochs.events[i, 2]\n",
    "\n",
    "        if epoch_label in [5, 6] or epoch_label not in STAGE_NAMES:\n",
    "            continue\n",
    "\n",
    "        stage_counts[epoch_label] += 1\n",
    "        npy_path = os.path.join(subfolder_path, f\"e{i:04d}_{epoch_label}.npy\")\n",
    "        np.save(npy_path, epoch_data[0])\n",
    "\n",
    "    return stage_counts\n",
    "\n",
    "def match_psg_annotation_files(psg_dir, annotation_dir):\n",
    "    psg_files = [f for f in os.listdir(psg_dir) if f.endswith('.edf')]\n",
    "    file_map = {}\n",
    "    for psg_file in psg_files:\n",
    "        base_id = re.sub(r'\\.edf$', '', psg_file)\n",
    "        base_id = re.sub(r'[\\-_].*$', '', base_id)\n",
    "        annotation_candidates = [\n",
    "            f for f in os.listdir(annotation_dir)\n",
    "            if f.startswith(base_id) and f.endswith('.xml')\n",
    "        ]\n",
    "        if annotation_candidates:\n",
    "            annotation_file = sorted(annotation_candidates, key=len, reverse=True)[0]\n",
    "            file_map[psg_file] = annotation_file\n",
    "    return file_map\n",
    "\n",
    "def main(max_files=6000):\n",
    "    ANNOTATION_DIR = \"D:/shhs/polysomnography/annotations-events-nsrr/shhs1\"\n",
    "    PSG_DIR = \"D:/shhs/polysomnography/edfs/shhs1\"\n",
    "    OUTPUT_DIR = \"E:/数据/shhs_staging\"\n",
    "\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    file_map = match_psg_annotation_files(PSG_DIR, ANNOTATION_DIR)\n",
    "    print(f\"找到 {len(file_map)} 对匹配的文件\")\n",
    "    global_stage_counts = {stage: 0 for stage in STAGE_NAMES.keys()}\n",
    "    processed_files = 0\n",
    "    \n",
    "\n",
    "    file_items = list(file_map.items())[:]\n",
    "    file_map = dict(file_items)\n",
    "    \n",
    "    for psg_file, annotation_file in tqdm(file_map.items(), desc=\"Processing files\"):\n",
    "        print(psg_file)\n",
    "        if processed_files >= max_files:\n",
    "            print(f\"已处理 {max_files} 个文件，停止处理.\")\n",
    "            break\n",
    "\n",
    "        psg_path = os.path.join(PSG_DIR, psg_file)\n",
    "        annotation_path = os.path.join(ANNOTATION_DIR, annotation_file)\n",
    "\n",
    "        raw, duration = read_and_preprocess_edf(psg_path)\n",
    "        if raw is None:\n",
    "            continue\n",
    "        \n",
    "        picked_channels = select_channels(raw)\n",
    "        if picked_channels is None:\n",
    "            continue\n",
    "\n",
    "        sleep_events = parse_sleep_annotations(annotation_path)\n",
    "        if sleep_events is None or not sleep_events:\n",
    "            continue\n",
    "\n",
    "        raw.pick_channels(picked_channels)\n",
    "        epochs = process_raw_data(raw, sleep_events, resample_freq=100)\n",
    "        if epochs is None or len(epochs) == 0:\n",
    "            continue\n",
    "\n",
    "        stage_counts = save_epochs_to_npy(epochs, OUTPUT_DIR, psg_file, processed_files + 1)\n",
    "        for stage, count in stage_counts.items():\n",
    "            global_stage_counts[stage] += count\n",
    "\n",
    "        processed_files += 1\n",
    "        print(f\"已处理 {processed_files} 个文件\")\n",
    "\n",
    "    print(\"\\n处理完成，最终统计数据:\")\n",
    "    for stage, count in global_stage_counts.items():\n",
    "        print(f\"阶段 {stage}: {count} 个epochs\")\n",
    "    print(f\"总计: {sum(global_stage_counts.values())} 个epochs\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(max_files=6000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85045273",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleep3.8",
   "language": "python",
   "name": "sleep3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
