{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ec990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import math\n",
    "import pywt\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "from mne import Annotations\n",
    "\n",
    "def wavelet_denoise(data, wavelet='sym6', level=5, mode='soft', boundary_mode='symmetric'):\n",
    "    if data.ndim != 2:\n",
    "        raise ValueError(f\"输入数据需为二维数组，当前维度：{data.ndim}\")\n",
    "    if mode not in ('soft', 'hard'):\n",
    "        raise ValueError(f\"无效阈值模式：{mode}，可选 'soft' 或 'hard'\")\n",
    "    \n",
    "    denoised_data = np.zeros_like(data)\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        channel_data = data[i, :]\n",
    "        try:\n",
    "            max_level = pywt.dwt_max_level(len(channel_data), pywt.Wavelet(wavelet))\n",
    "            actual_level = min(level, max_level) if max_level else level\n",
    "            coeffs = pywt.wavedec(channel_data, wavelet, level=actual_level, mode=boundary_mode)\n",
    "            detail_coeffs = coeffs[-1]\n",
    "            sigma = np.median(np.abs(detail_coeffs)) / 0.6745 if len(detail_coeffs) else 0\n",
    "            n = len(channel_data)\n",
    "            threshold = sigma * np.sqrt(2 * np.log(n)) if sigma > 0 else 0\n",
    "            coeffs_thresholded = [coeffs[0]]\n",
    "            for j in range(1, len(coeffs)):\n",
    "                c = coeffs[j]\n",
    "                c_thresh = pywt.threshold(c, threshold, mode=mode)\n",
    "                coeffs_thresholded.append(c_thresh)\n",
    "            denoised_channel = pywt.waverec(coeffs_thresholded, wavelet, mode=boundary_mode)\n",
    "            if len(denoised_channel) > len(channel_data):\n",
    "                denoised_data[i, :] = denoised_channel[:len(channel_data)]\n",
    "            else:\n",
    "                denoised_data[i, :len(denoised_channel)] = denoised_channel\n",
    "        except pywt.Error as e:\n",
    "            raise RuntimeError(f\"小波处理异常，通道{i}错误：{str(e)}\") from e\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"通道{i}处理失败：{str(e)}\") from e\n",
    "    return denoised_data\n",
    "\n",
    "def generate_stage_annotations(xml_path, epoch_length=30, total_duration=None):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    stage_events = []\n",
    "    for event in root.iter('ScoredEvent'):\n",
    "        event_type = event.findtext('EventType', '').strip()\n",
    "        if event_type != 'Stages|Stages':\n",
    "            continue\n",
    "        concept = event.findtext('EventConcept', '')\n",
    "        parts = [p.strip() for p in concept.split('|')]\n",
    "        if len(parts) < 2 or not parts[1].isdigit():\n",
    "            print(f\"[WARNING] 未能正确解析 EventConcept: {concept}，跳过此事件\")\n",
    "            continue\n",
    "        raw_label = int(parts[1])\n",
    "        label = 4 if raw_label == 5 else raw_label\n",
    "        if not (0 <= label <= 4):\n",
    "            continue\n",
    "        try:\n",
    "            start = float(event.findtext('Start', '0'))\n",
    "            duration = float(event.findtext('Duration', '0'))\n",
    "        except ValueError as e:\n",
    "            print(f\"[ERROR] 解析 Start 或 Duration 时出错: {e}, EventConcept: {concept}\")\n",
    "            continue\n",
    "        if duration <= 0 or start < 0:\n",
    "            continue\n",
    "        stage_events.append({'start': start, 'end': start + duration, 'label': label})\n",
    "    max_time = total_duration if total_duration is not None else max([e['end'] for e in stage_events] + [0])\n",
    "    total_epochs = math.ceil(max_time / epoch_length)\n",
    "    annotations = [{'epoch': i, 'label': 0} for i in range(total_epochs)]\n",
    "    for e in stage_events:\n",
    "        start_epoch = max(0, int(e['start'] // epoch_length))\n",
    "        end_epoch = min(total_epochs-1, int((e['end']-1e-9) // epoch_length))\n",
    "        for i in range(start_epoch, end_epoch + 1):\n",
    "            annotations[i]['label'] = e['label']\n",
    "    return annotations\n",
    "\n",
    "def process_psg_with_segmentation(edf_path, xml_path, output_dir, channels=None, epoch_length=30, resample_rate=None):\n",
    "    try:\n",
    "        raw = mne.io.read_raw(edf_path, preload=True, verbose=False)\n",
    "        \n",
    "        if resample_rate:\n",
    "            print(f\"[INFO] 下采样为 {resample_rate} Hz\")\n",
    "            raw.resample(sfreq=resample_rate)\n",
    "        \n",
    "        if channels:\n",
    "            existing = [ch for ch in channels if ch in raw.ch_names]\n",
    "            missing = set(channels) - set(existing)\n",
    "            if missing:\n",
    "                print(f\"[WARNING] 缺失通道: {missing}\")\n",
    "            raw.pick_types(eeg=True, include=existing)\n",
    "\n",
    "        stage_anns = generate_stage_annotations(xml_path)\n",
    "        print(f\"[INFO] 正在处理文件: {edf_path}\")\n",
    "        segment_idx = 0\n",
    "        sfreq = raw.info['sfreq']\n",
    "        samples_per_epoch = int(epoch_length * sfreq)\n",
    "        data = raw.get_data()\n",
    "\n",
    "        for epoch_idx in range(len(stage_anns)):\n",
    "            stage_label = stage_anns[epoch_idx]['label']\n",
    "            segment_data = data[:, epoch_idx * samples_per_epoch: (epoch_idx + 1) * samples_per_epoch]\n",
    "            filename = f\"ex{segment_idx:04d}_{stage_label}.npy\"\n",
    "            np.save(os.path.join(output_dir, filename), segment_data)\n",
    "            segment_idx += 1\n",
    "        print(f\"[INFO] 完成文件: {edf_path} 的处理，共保存 {segment_idx} 个片段\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] 处理文件 {edf_path} 时发生错误: {e}\")\n",
    "        return\n",
    "\n",
    "# ==== 配置参数 ====\n",
    "edf_dir = \"E:/mesa/polysomnography/edfs\"\n",
    "xml_dir = \"E:/mesa/polysomnography/annotations-events-nsrr\"\n",
    "output_base_dir = \"G:/mesa_staging\"\n",
    "\n",
    "n_files = 3000\n",
    "channels = ['EEG2', 'Flow', 'SpO2', 'Thor', 'Abdo']\n",
    "denoise_enabled = True\n",
    "normalize_enabled = True\n",
    "resample_rate = 100  # 设置目标采样率，如不下采样则设为 None\n",
    "\n",
    "edf_files = glob.glob(os.path.join(edf_dir, \"mesa-sleep-*.edf\"))\n",
    "edf_files.sort(key=lambda x: int(re.search(r'mesa-sleep-(\\d+)\\.edf', os.path.basename(x)).group(1)))\n",
    "if isinstance(n_files, int):\n",
    "    edf_files = edf_files[:n_files]\n",
    "    print(f\"准备处理前 {n_files} 个文件\")\n",
    "\n",
    "total_files = len(edf_files)\n",
    "processed_count = 0\n",
    "failed_count = 0\n",
    "\n",
    "for edf_path in edf_files:\n",
    "    try:\n",
    "        base_name = os.path.basename(edf_path)\n",
    "        file_id = re.search(r'mesa-sleep-(\\d+)\\.edf', base_name).group(1)\n",
    "        xml_filename = f\"mesa-sleep-{file_id}-nsrr.xml\"\n",
    "        xml_path = os.path.join(xml_dir, xml_filename)\n",
    "        if not os.path.exists(xml_path):\n",
    "            print(f\"[SKIP] 缺失标注文件: {xml_filename}\")\n",
    "            continue\n",
    "        output_dir = os.path.join(output_base_dir, file_id)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        processed_count += 1\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"正在处理文件 ({processed_count}/{total_files}): {base_name}\")\n",
    "        process_psg_with_segmentation(\n",
    "            edf_path=edf_path,\n",
    "            xml_path=xml_path,\n",
    "            output_dir=output_dir,\n",
    "            channels=channels,\n",
    "            epoch_length=30,\n",
    "            resample_rate=resample_rate\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] 处理文件 {base_name} 失败: {str(e)}\")\n",
    "        failed_count += 1\n",
    "        continue\n",
    "\n",
    "print(\"\\n批量处理完成！处理情况：\")\n",
    "print(f\"总文件数: {total_files}\")\n",
    "print(f\"成功处理: {processed_count}\")\n",
    "print(f\"失败文件: {failed_count}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleep3.8",
   "language": "python",
   "name": "sleep3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
